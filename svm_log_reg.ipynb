{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6adb2616-db02-4a09-8f7d-5f9015be6963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# For reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a37da208-eccc-4560-8d88-1adc79b12c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 1. Load and inspect dataset\n",
    "# ===============================\n",
    "\n",
    "file_path = \"titanic.csv\"  # Adjust path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e407f12b-8203-40a8-b931-da7d08c0998e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (891, 8)\n",
      "Shape of y: (891,)\n",
      "Train shape (std): (712, 8)\n",
      "Test shape (std): (179, 8)\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# 2. Preprocess: clean, encode, scale\n",
    "# =======================================\n",
    "\n",
    "# Drop non-numeric / ID-heavy columns\n",
    "df_model = df.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"])\n",
    "\n",
    "# Handle missing values\n",
    "df_model[\"Age\"] = df_model[\"Age\"].fillna(df_model[\"Age\"].median())\n",
    "df_model[\"Embarked\"] = df_model[\"Embarked\"].fillna(df_model[\"Embarked\"].mode()[0])\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df_model = pd.get_dummies(df_model, columns=[\"Sex\", \"Embarked\"], drop_first=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_model.drop(columns=[\"Survived\"]).values\n",
    "y = df_model[\"Survived\"].values\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "# Train-test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Feature scaling (VERY important for SVM & PCA)\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "print(\"Train shape (std):\", X_train_std.shape)\n",
    "print(\"Test shape (std):\", X_test_std.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28729be-828b-491b-adbb-eea5b82919c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA train shape: (712, 7)\n",
      "PCA test shape: (179, 7)\n",
      "Explained variance (PCA): 0.9548692220455597\n",
      "Explained variance per component: [0.22969511 0.21202173 0.19070433 0.10363124 0.09594764 0.07040417\n",
      " 0.05246499]\n"
     ]
    }
   ],
   "source": [
    "# =========\n",
    "# 3. PCA\n",
    "# =========\n",
    "\n",
    "# Keep 95% of the variance\n",
    "pca = PCA(n_components=0.95, random_state=RANDOM_STATE)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "print(\"PCA train shape:\", X_train_pca.shape)\n",
    "print(\"PCA test shape:\", X_test_pca.shape)\n",
    "print(\"Explained variance (PCA):\", pca.explained_variance_ratio_.sum())\n",
    "print(\"Explained variance per component:\", pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84149ec1-9bf8-46e8-82cd-906071f9a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 4. Linear SVM from scratch (GD)\n",
    "# ==================================\n",
    "\n",
    "class LinearSVM:\n",
    "    \"\"\"\n",
    "    Simple linear SVM with hinge loss and L2 regularization,\n",
    "    optimized via (vectorized) batch gradient descent.\n",
    "    \"\"\"\n",
    "    def __init__(self, C=1.0, lr=0.001, n_iters=1000, verbose=False):\n",
    "        self.C = C\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.verbose = verbose\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Map labels from {0,1} to {-1, +1}\n",
    "        y_ = np.where(y <= 0, -1, 1).astype(float)\n",
    "\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0.0\n",
    "\n",
    "        for it in range(self.n_iters):\n",
    "            # Decision scores\n",
    "            scores = X @ self.w - self.b\n",
    "            margins = y_ * scores\n",
    "\n",
    "            # Points that violate margin (hinge loss active)\n",
    "            misclassified = margins < 1\n",
    "\n",
    "            if np.any(misclassified):\n",
    "                # Gradient for w: w - C * (sum(y_i * x_i) over misclassified) / n_samples\n",
    "                dw = self.w - self.C * (X[misclassified].T @ y_[misclassified]) / n_samples\n",
    "                # Gradient for b: C * mean(y_i) over misclassified\n",
    "                db = -self.C * np.mean(y_[misclassified])\n",
    "            else:\n",
    "                # Only regularization if nothing misclassified\n",
    "                dw = self.w\n",
    "                db = 0.0\n",
    "\n",
    "            # Update parameters\n",
    "            self.w -= self.lr * dw\n",
    "            self.b -= self.lr * db\n",
    "\n",
    "            # Optional: monitor loss every few iterations\n",
    "            if self.verbose and (it + 1) % 100 == 0:\n",
    "                loss = self._compute_loss(X, y_)\n",
    "                print(f\"Iter {it+1}/{self.n_iters} - loss: {loss:.4f}\")\n",
    "\n",
    "    def _compute_loss(self, X, y_):\n",
    "        # Hinge loss + regularization (for monitoring only)\n",
    "        scores = X @ self.w - self.b\n",
    "        margins = 1 - y_ * scores\n",
    "        hinge_loss = np.maximum(0, margins).mean()\n",
    "        reg_term = 0.5 * np.dot(self.w, self.w)\n",
    "        return reg_term + self.C * hinge_loss\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return X @ self.w - self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        scores = self.decision_function(X)\n",
    "        return (scores >= 0).astype(int)  # Map back to {0,1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aafe1b01-c024-425a-bd08-047dab386654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. Helper function: evaluate a classifier\n",
    "# ==========================================\n",
    "\n",
    "def evaluate_model(name, model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Accuracy:\", f\"{acc:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\",\n",
    "          classification_report(y_test, y_pred, digits=4, zero_division=0))\n",
    "    \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1270a30a-2c56-4aae-8267-a25997eeea17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression (no PCA) ===\n",
      "Accuracy: 0.8045\n",
      "Confusion Matrix:\n",
      " [[98 12]\n",
      " [23 46]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8099    0.8909    0.8485       110\n",
      "           1     0.7931    0.6667    0.7244        69\n",
      "\n",
      "    accuracy                         0.8045       179\n",
      "   macro avg     0.8015    0.7788    0.7864       179\n",
      "weighted avg     0.8034    0.8045    0.8007       179\n",
      "\n",
      "\n",
      "=== Logistic Regression (with PCA) ===\n",
      "Accuracy: 0.8101\n",
      "Confusion Matrix:\n",
      " [[98 12]\n",
      " [22 47]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8167    0.8909    0.8522       110\n",
      "           1     0.7966    0.6812    0.7344        69\n",
      "\n",
      "    accuracy                         0.8101       179\n",
      "   macro avg     0.8066    0.7860    0.7933       179\n",
      "weighted avg     0.8089    0.8101    0.8068       179\n",
      "\n",
      "\n",
      "=== Linear SVM from scratch (no PCA) ===\n",
      "Accuracy: 0.6313\n",
      "Confusion Matrix:\n",
      " [[55 55]\n",
      " [11 58]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    0.5000    0.6250       110\n",
      "           1     0.5133    0.8406    0.6374        69\n",
      "\n",
      "    accuracy                         0.6313       179\n",
      "   macro avg     0.6733    0.6703    0.6312       179\n",
      "weighted avg     0.7100    0.6313    0.6298       179\n",
      "\n",
      "\n",
      "=== Linear SVM from scratch (with PCA) ===\n",
      "Accuracy: 0.6480\n",
      "Confusion Matrix:\n",
      " [[58 52]\n",
      " [11 58]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8406    0.5273    0.6480       110\n",
      "           1     0.5273    0.8406    0.6480        69\n",
      "\n",
      "    accuracy                         0.6480       179\n",
      "   macro avg     0.6839    0.6839    0.6480       179\n",
      "weighted avg     0.7198    0.6480    0.6480       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# 6. Train & evaluate all models (4 variants)\n",
    "# ===========================================\n",
    "\n",
    "results = {}\n",
    "\n",
    "# (a) Logistic Regression without PCA\n",
    "log_reg = LogisticRegression(max_iter=2000, random_state=RANDOM_STATE)\n",
    "log_reg.fit(X_train_std, y_train)\n",
    "results[\"LogReg (no PCA)\"] = evaluate_model(\n",
    "    \"Logistic Regression (no PCA)\", log_reg, X_test_std, y_test\n",
    ")\n",
    "\n",
    "# (b) Logistic Regression with PCA\n",
    "log_reg_pca = LogisticRegression(max_iter=2000, random_state=RANDOM_STATE)\n",
    "log_reg_pca.fit(X_train_pca, y_train)\n",
    "results[\"LogReg (with PCA)\"] = evaluate_model(\n",
    "    \"Logistic Regression (with PCA)\", log_reg_pca, X_test_pca, y_test\n",
    ")\n",
    "\n",
    "# (c) SVM from scratch without PCA\n",
    "svm = LinearSVM(C=1.0, lr=0.001, n_iters=1000, verbose=False)\n",
    "svm.fit(X_train_std, y_train)\n",
    "results[\"SVM (no PCA, scratch)\"] = evaluate_model(\n",
    "    \"Linear SVM from scratch (no PCA)\", svm, X_test_std, y_test\n",
    ")\n",
    "\n",
    "# (d) SVM from scratch with PCA\n",
    "svm_pca = LinearSVM(C=1.0, lr=0.001, n_iters=1000, verbose=False)\n",
    "svm_pca.fit(X_train_pca, y_train)\n",
    "results[\"SVM (with PCA, scratch)\"] = evaluate_model(\n",
    "    \"Linear SVM from scratch (with PCA)\", svm_pca, X_test_pca, y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a89d2b-fc3c-42f8-b5f8-a06495a81c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Summary of Accuracies ==========\n",
      "LogReg (no PCA)               : 0.8045\n",
      "LogReg (with PCA)             : 0.8101\n",
      "SVM (no PCA, scratch)         : 0.6313\n",
      "SVM (with PCA, scratch)       : 0.6480\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg (no PCA)</th>\n",
       "      <td>0.804469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg (with PCA)</th>\n",
       "      <td>0.810056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM (no PCA, scratch)</th>\n",
       "      <td>0.631285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM (with PCA, scratch)</th>\n",
       "      <td>0.648045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy\n",
       "LogReg (no PCA)          0.804469\n",
       "LogReg (with PCA)        0.810056\n",
       "SVM (no PCA, scratch)    0.631285\n",
       "SVM (with PCA, scratch)  0.648045"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================\n",
    "# 7. Final summary\n",
    "# ==================\n",
    "\n",
    "print(\"\\n========== Summary of Accuracies ==========\")\n",
    "for model_name, acc in results.items():\n",
    "    print(f\"{model_name:30s}: {acc:.4f}\")\n",
    "\n",
    "# Optional: show as DataFrame\n",
    "summary_df = pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Accuracy\"])\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2514eed-dca9-439d-b236-18372bf367cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
