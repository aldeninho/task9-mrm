{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e6b9b73-8e44-47c3-ab4e-2dcce52be28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (891, 8)\n",
      "Shape of y: (891,)\n",
      "Train shape: (712, 8)\n",
      "Test shape: (179, 8)\n",
      "PCA train shape: (712, 7)\n",
      "PCA test shape: (179, 7)\n",
      "Explained variance (PCA): 0.9548692220455597\n",
      "\n",
      "=== Logistic Regression (no PCA) ===\n",
      "Accuracy: 0.8044692737430168\n",
      "Confusion Matrix:\n",
      " [[98 12]\n",
      " [23 46]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       110\n",
      "           1       0.79      0.67      0.72        69\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.78      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n",
      "\n",
      "=== Logistic Regression (with PCA) ===\n",
      "Accuracy: 0.8100558659217877\n",
      "Confusion Matrix:\n",
      " [[98 12]\n",
      " [22 47]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       110\n",
      "           1       0.80      0.68      0.73        69\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.81      0.79      0.79       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n",
      "\n",
      "=== SVM from scratch (no PCA) ===\n",
      "Accuracy: 0.3854748603351955\n",
      "Confusion Matrix:\n",
      " [[  0 110]\n",
      " [  0  69]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       110\n",
      "           1       0.39      1.00      0.56        69\n",
      "\n",
      "    accuracy                           0.39       179\n",
      "   macro avg       0.19      0.50      0.28       179\n",
      "weighted avg       0.15      0.39      0.21       179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM from scratch (with PCA) ===\n",
      "Accuracy: 0.3854748603351955\n",
      "Confusion Matrix:\n",
      " [[  0 110]\n",
      " [  0  69]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       110\n",
      "           1       0.39      1.00      0.56        69\n",
      "\n",
      "    accuracy                           0.39       179\n",
      "   macro avg       0.19      0.50      0.28       179\n",
      "weighted avg       0.15      0.39      0.21       179\n",
      "\n",
      "\n",
      "========== Summary of Accuracies ==========\n",
      "LogReg (no PCA): 0.8045\n",
      "LogReg (with PCA): 0.8101\n",
      "SVM (no PCA, scratch): 0.3855\n",
      "SVM (with PCA, scratch): 0.3855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# ===============================\n",
    "# 1. Load and preprocess dataset\n",
    "# ===============================\n",
    "\n",
    "# Adjust the path if needed\n",
    "file_path = \"titanic.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop non-numeric / ID-heavy columns\n",
    "df_model = df.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"])\n",
    "\n",
    "# Handle missing values\n",
    "df_model[\"Age\"] = df_model[\"Age\"].fillna(df_model[\"Age\"].median())\n",
    "df_model[\"Embarked\"] = df_model[\"Embarked\"].fillna(df_model[\"Embarked\"].mode()[0])\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df_model = pd.get_dummies(df_model, columns=[\"Sex\", \"Embarked\"], drop_first=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_model.drop(columns=[\"Survived\"]).values\n",
    "y = df_model[\"Survived\"].values\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "print(\"Train shape:\", X_train_std.shape)\n",
    "print(\"Test shape:\", X_test_std.shape)\n",
    "\n",
    "# =========\n",
    "# 2.  PCA\n",
    "# =========\n",
    "\n",
    "# Keep 95% of the variance\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "print(\"PCA train shape:\", X_train_pca.shape)\n",
    "print(\"PCA test shape:\", X_test_pca.shape)\n",
    "print(\"Explained variance (PCA):\", pca.explained_variance_ratio_.sum())\n",
    "\n",
    "# ============================\n",
    "# 3. SVM from scratch (Linear)\n",
    "# ============================\n",
    "\n",
    "class LinearSVM:\n",
    "    \"\"\"\n",
    "    Simple linear SVM with hinge loss and L2 regularization,\n",
    "    optimized via (very basic) gradient descent.\n",
    "    \"\"\"\n",
    "    def __init__(self, C=1.0, lr=0.001, n_iters=1000):\n",
    "        self.C = C\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Map labels from {0,1} to {-1, +1}\n",
    "        y_ = np.where(y <= 0, -1, 1)\n",
    "\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0.0\n",
    "\n",
    "        lambda_param = 1.0 / self.C\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                condition = y_[idx] * (np.dot(x_i, self.w) - self.b) >= 1\n",
    "\n",
    "                if condition:\n",
    "                    # Only regularization term\n",
    "                    dw = 2 * lambda_param * self.w\n",
    "                    db = 0.0\n",
    "                else:\n",
    "                    # Regularization + hinge loss gradient\n",
    "                    dw = 2 * lambda_param * self.w - y_[idx] * x_i\n",
    "                    db = -y_[idx]\n",
    "\n",
    "                # Gradient descent update\n",
    "                self.w -= self.lr * dw\n",
    "                self.b -= self.lr * db\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return np.dot(X, self.w) - self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        approx = self.decision_function(X)\n",
    "        # Map back to {0,1}\n",
    "        return np.where(approx >= 0, 1, 0)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 4. Train & evaluate all models\n",
    "# ================================\n",
    "\n",
    "results = {}\n",
    "\n",
    "# (a) Logistic Regression without PCA\n",
    "log_reg = LogisticRegression(max_iter=2000)\n",
    "log_reg.fit(X_train_std, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test_std)\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "results[\"LogReg (no PCA)\"] = acc_lr\n",
    "\n",
    "print(\"\\n=== Logistic Regression (no PCA) ===\")\n",
    "print(\"Accuracy:\", acc_lr)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# (b) Logistic Regression with PCA\n",
    "log_reg_pca = LogisticRegression(max_iter=2000)\n",
    "log_reg_pca.fit(X_train_pca, y_train)\n",
    "y_pred_lr_pca = log_reg_pca.predict(X_test_pca)\n",
    "acc_lr_pca = accuracy_score(y_test, y_pred_lr_pca)\n",
    "results[\"LogReg (with PCA)\"] = acc_lr_pca\n",
    "\n",
    "print(\"\\n=== Logistic Regression (with PCA) ===\")\n",
    "print(\"Accuracy:\", acc_lr_pca)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr_pca))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr_pca))\n",
    "\n",
    "# (c) SVM from scratch without PCA\n",
    "svm = LinearSVM(C=1.0, lr=0.001, n_iters=500)\n",
    "svm.fit(X_train_std, y_train)\n",
    "y_pred_svm = svm.predict(X_test_std)\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "results[\"SVM (no PCA, scratch)\"] = acc_svm\n",
    "\n",
    "print(\"\\n=== SVM from scratch (no PCA) ===\")\n",
    "print(\"Accuracy:\", acc_svm)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# (d) SVM from scratch with PCA\n",
    "svm_pca = LinearSVM(C=1.0, lr=0.001, n_iters=500)\n",
    "svm_pca.fit(X_train_pca, y_train)\n",
    "y_pred_svm_pca = svm_pca.predict(X_test_pca)\n",
    "acc_svm_pca = accuracy_score(y_test, y_pred_svm_pca)\n",
    "results[\"SVM (with PCA, scratch)\"] = acc_svm_pca\n",
    "\n",
    "print(\"\\n=== SVM from scratch (with PCA) ===\")\n",
    "print(\"Accuracy:\", acc_svm_pca)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm_pca))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm_pca))\n",
    "\n",
    "# ==================\n",
    "# 5. Final summary\n",
    "# ==================\n",
    "\n",
    "print(\"\\n========== Summary of Accuracies ==========\")\n",
    "for model_name, acc in results.items():\n",
    "    print(f\"{model_name}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acbdc23-a619-4f2b-9171-cb4121273976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
